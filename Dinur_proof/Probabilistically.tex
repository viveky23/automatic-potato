\textcolor{red}{\textbf{Abstract:} }

In order to verify some property using PCP, the prover needs to present a proof $P$ which is \textbf{easily testable}. Testing can be done by querying the proof at $q(n)$ points where $q(n)$ is a small number. PCP needs to satisfy the following properties: 
\begin{enumerate}[nolistsep]
    \item If the property actually holds, the verifier should always (or almost always) accept.
    \item If the property doesn't hold, then the verifier would notice with some constant probability.
\end{enumerate}

To account for lengthy proofs, as the verifier will only be looking at a small number- $q(n)$ points, randomness in choosing points is encouraged so as to make it harder to fool the verifier. The verifier chooses $r(n)$ random coins, and based on them queries the proof at $q(n)$ points. Then she applies a test which always succeeds in YES instances (the property holds), but fails with constant probability (over the coin tosses) in NO instances (the property doesn't hold). Since there are $r(n)$ coins, there are $2^{r(n)}$ different outcomes for the coins, and so the verifier in total queries the proof in at most $2^{r(n)}q(n)$ different places.

We use PCP because we can encode the verifier as a CNF whose variables are bits of the proof, for all $2^{r(n)}$ coin tosses, there exist clauses encoding that the $q(n)$ bits that were sampled, do pass the verifier's test. In case of a positive, $YES$ instance the CNF is always satisfiable and in case of a negative, $NO$ instance we see failure with some constant probability leading to a fraction of the clauses always being unsatisfied. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Basics}
We describe a verifier such that for any yes instance of $X$, there exists a certificate that the verifier will accept, and for any no instance of $X$, no such certificate exists. The running time of the verifier (and hence the size of the certificate) must be polynomial. This is formally represented as a function $V: \{0,1\}* \times \{0,1\}* \rightarrow \{0,1\}$ where, $V(T,\pi) = 1$ implies $\pi$ is the proof of assertion $T$, making it a proof. Classical verifiers/algorithms are enhanced by giving them access to random strings and oracles. Oracles will be functions $O: Q \rightarrow A$ with $Q$ being a countable set and $A$ being a finite set. In the query model, you are given
black-box access to some function $f$. You have to answer some question about $f$. 

Instead of measuring the time complexity of your algorithm, we measure the query complexity: the number of queries it makes to f. A probabilistic algorithm $A(·, ·)$ is an algorithm that takes two inputs $x$ and $r$, where $x$ is an instance of some problem that we want to solve, and $r$ is the output of a random source. A random source is an idealized device that outputs a sequence of bits that are uniformly and independently distributed. The output of a probabilistic oracle algorithm $A$ on input $x$, random string $R \in \{0,1\}*$ and access to oracle $O$ will be denoted as $A^O(x,R)$.

\textbf{Definition 1} \textit{For functions r,q,a : $\mathbb{Z}^+ \rightarrow \mathbb{Z}^+$ an (r,q,a) restricted PCP verifier is a probabbilistic oracle algorithm V that on input $x \in \{0,1\}^n$ expects a random string $R \in \{0,1\}^{r(n)}$ and queries an oracle $\pi : \mathbb{Z}^+ \rightarrow \{0,1\}^{a(n)}$ at most q(n) times and computes a "Boolean verdict" $V^{\pi}(x,R) \in \{0,1\}$.}

\textbf{Definition 2} \textit{For positive constant $0 \leq s \leq 1$, we can say that an (r,q,a)-restricted PCP verifier v accepts a language $L \subseteq \{0,1\}^*$ with soundness s if for every $x \in \{0,1\}^n the following hold:$}

\textbf{Completeness} \textit{If $x \in L$ then there exists a $\pi : \mathbb{Z}^+ \rightarrow \{0,1\}^{a(n)}$ such that for every $R$, $V^{\pi}(x:R) = 1$}

\textbf{Soundness} \textit{If $x \notin L$ then for every $\pi : \mathbb{Z}^+ \rightarrow \{0,1\}^{a(n)}$} it is the case that $Pr_R[\pi : \mathbb{Z}^+ \rightarrow \{0,1\}^{a(n)}] \leq s$

\textit{By $PCP_s[r,q,a]$ we denote a class of all languages L such that there exists an (r,q,a) restricted PCP verifier accepting L with soundness s.} The above definition is called a non-adaptive verifier. An adaptive verifier accesses y one bit at a time and may adapt its computation according to the read bit. In our definition V has a fixed predicate , and simply outputs that predicate in the final step. The length of the proof $\pi$ is at most $2^rq$ since there are $2r$ possible random strings of length $r$ and, $q$ possible accesses for each string. Therefore if $r$ is $c log n(n = |x|)$ for some constant $c$, the proof $y$ is of length at most $n^cq$, i.e. polynomial in n.

The soundness error can, as usual, be reduced by repetition. For exponentially-small error, this does not affect the class PCP; however, such repetition affects the parameters r, q. (E.g., if $L \in PCP(r, q)$ by the above definition then $L \in PCP^∗(|x|.r, |x|.q)$ if by $PCP^∗$ we mean that we require soundness error $2^{−|x|}$.)

\textbf{Theorem 1} \textit{The PCP Theorem: There exists two constant numbers c1 and c2 such that $NP = PCP[c_1 log n, c_2]$. For simplicity, $NP = PCP[O(log n), O(1)]$.}

\textbf{Theorem 2} Hastad (1997) Theorem [2] For every constant $\epsilon, \delta > 0, NP = PCP_{1 - \epsilon,1/2+\delta} [O(log n), 3]$ 

That is, for every constant $\epsilon, \delta > 0$, there is a poly-size PCP for NP that reads just three random bits and test their XOR. Its completeness is $1 - \epsilon$ and its soundness is $1/2 + \epsilon$. This result has imperfect completeness. However, if one is willing to allow an adaptive three-bit-querying verifier, i.e. the verifier $V$ does not have to pick the three bits in advance but can base what bit it reads next on what it’s seen so far, then one can get completeness 1. That is, $NP = PCP_{1,1/2+\delta}[O(log n), O(1)]$. This result is due to Guruswami, Lewin,
Sudan, and Trevisan [REFERENCE].

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Formulations of PCP}
The PCP theorem has many applications, in particular to hardness of approximation. We discuss three equivalent formulations of the theorem. All three state that a certain problem is NP-complete.

\subsection{Proof Checking Version}
All NP languages have proofs that can be verified very efficiently as only a constant number of symbols of the proof need to be evaluated given that we use a probabilistic decision process which gives errors with a small probability. Given the definition of the PCP verifier and the associated complexity class, the PCP theorem states that alllanguages in NP have very efficient verifiers i.e. those which only read a constant number of bits from the proof.

\textbf{Theorem 3} \textit{Given the specification of a verifier $V$ and $x \in \{0, 1\}^*$ we let $\omega (V_x)$ be the maximum acceptance probability of $V$, when its input is $x$ and the maximum is taken over all possible proofs $\pi \in \epsilon^*$. The inclusion $NP \subseteq PCP(O(\log n))$, $O(1))$ holds. Equivalently, given a $((O(\log n), O(1))_{\{0,1\}}$-PCP verifier V, the problem of deciding between $\omega(V_x) = 1$ and $\omega(V_x) \leq 1/2$ is NP-hard.}

\subsection{Multiplayer Games}
The discovery of the surprising power of randomization, interaction, and multiple provers eventually led to the proof of the PCP theorem. Here we give a statement of the theorem in the language of multiplayer games, which provide a convenient framework in which to express “scaled-down” variants (corresponding to interactions involving a single round of question/answers, and a polynomial number of possible questions) of the MIP = NEXP result.

\textbf{Definition 3} \textit{Let q be an integer. A q-player game G is specified by the following:
\begin{enumerate}
    \item Finite question sets $Q_1,..., Q_q$,
    \item A probability distribution $\pi$ on $Q_1 \times ... Q_q$,
    \item Finite answer sets $A_1, . . . , A_q$,
    \item A decision predicate $V : (A_1 \times ... \times A_q) \times (Q_1 \times ... \times Q_q) \rightarrow \{0, 1\}$.
\end{enumerate}
Given a game G, the value $\omega(G)$ of G is defined as the maximum success probability of players $P_1, ... , P_q$ in the game, where player $P_j$ is simply a deterministic function $f_j: Q_j \rightarrow A_j$. Formally,
$$\omega(G) = \max_{f_j:Q_j \rightarrow A_j} \sum_{(q_1,...,q_q) \in Q_1 \times ... \times Q_q} \pi (q_1, ..., q_q) V (f_1(q_1), ... , f_q(q_q); q_1, ..., q_q)$$}

Giving us another formulation of the PCP theorem as follows:

\textbf{Theorem 4} \textit{For any $L \in NP$ there exists a polynomial-time mapping $x \in \{0, 1\}^* \rightarrow G_x$ from strings x to q-player games $G_x$, where $q = O(1)$, such that $x \in L \rightarrow \omega(G_x) = 1$ and $x \notin L \rightarrow \omega (G_x) \leq 1/2$. Equivalently, there exists a constant q such that the problem of deciding whether, given a q-player game G, $\omega (G) = 1$ or $\omega(G) \leq 1/2$, is NP-hard}

\subsection{Constraint Satisfaction Problems}
Our third formulation of the PCP theorem uses the language of constraint satisfaction problems, and is the most useful for applications to hardness of approximation.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{PCPs and Approximations}
The PCP theorem gives a PCP for 3SAT with $q(n) = O(\log n)$ and $r(n) = O(1)$. That means that given a 3CNF, we can come construct a new CNF of length $O(2^{q(n)}) = n^{O(1)}$ using the construction outlined in the preceding paragraph such that (i) if the original 3CNF formula is satisfiable, so is the new one, (ii) otherwise, at most $1-\epsilon$ fraction of the clauses can ever be satisfied in the new CNF. That gives a hardness of approximation result for 3SAT. 

Using Raz's parallel repetition theorem, Håstad obtained a construct in which in case (ii), at most $7/8+\epsilon$ of the clauses can be satisfied, thus obtaining an optimal inapproximability result. (It's optimal since a random assignment satisfies $7/8$ of the clauses; this algorithm can be derandomized using the method of conditional expectations.)

Given graph $G = (V,E)$ and integer $k$, find a coloring $A : V \rightarrow \{1,...,k\}$ that maximizes the number of satisfied edges, where an edge $e = \{u,v\}$ is said to be satisfied if $A(u) \neq A(v)$. We know that this maximization problem is NP-complete but is it hard to compute a coloring where atleast $0.999k$ edges are satisfied.

\textbf{Definition 3 (Constraint graph, coloring)}

\textbf{Constraint Graph:} \textit{A constraint graph G is a tuple $\langle V, E, \sigma, C \rangle$}, where $(V,E)$ is an undirected graph (allowing multiple edges and self-loops), $\sigma$ is a finite set called the alphabet of G, and C is a collection of constraints, $\langle c_e : e \in E \rangle$, where each $c_e$ is a function from $\sigma \times \sigma$ to $\{0,1\}$.

\textbf{Coloring and Satisfaction:} \textit{A coloring of G is a function $A : V \rightarrow \sigma$. We say that the coloring A satisfies an edge $e = \{u,v\}$, if $c_e(A(u),A(v)) = 1$. We say that the coloring A satisfies G, if A satisfes all edges of G. If there is a coloring that satisfies G, then we say that g is satisfiable. We say that G is $\epsilon-far$ from satisfiable if every coloring leaves at least a fraction $\epsilon$ of the edges of G unsatisfied. Let $$UNSAT(G) = \max \{\epsilon : G is \epsilon -satisfiable\} = \min_A \frac{\arrowvert\{e : A does not satisfy e\}\arrowvert}{\arrowvert E \arrowvert}$$ We use $G_K$ to denote the set of constraint graphs with an alphabet size of K.}
